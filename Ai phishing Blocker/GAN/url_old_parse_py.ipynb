{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3U2Arevfei2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b31c59-cd74-40ea-feba-535ea02bf776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ltqpp.research.google.com/drive/1vwjmMsSW8pFrQgYipbTdmoD9FCzBW7W_\n",
            "[[0, 0, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sqlalchemy.engine import result\n",
        "from requests.models import Response\n",
        "import  requests\n",
        "import re\n",
        "import urllib\n",
        "from urllib.parse import urlparse\n",
        "# from tld import get_tld\n",
        "from bs4 import BeautifulSoup\n",
        "# import whois\n",
        "import socket\n",
        "import ipaddress\n",
        "from datetime import datetime\n",
        "\n",
        "class url_data:\n",
        "    def __init__(self,url):\n",
        "        self.url=url\n",
        "#function to check the ip address\n",
        "def have_ip(url):\n",
        "  try:\n",
        "    ipaddress.ip_address(url)\n",
        "    ip=1\n",
        "  except:\n",
        "    ip=0\n",
        "  return ip\n",
        "\n",
        "#function to check At @\n",
        "def have_at(url):\n",
        "  return 1 if '@' in url else 0\n",
        "\n",
        "#function to check length of the url\n",
        "def length_url(url):\n",
        "  return 1 if len(url)>54 else 0\n",
        "\n",
        "#function to check url_depth\n",
        "def url_depth(url):\n",
        "  return url.count('/')-2\n",
        "  # s = url.split('/')\n",
        "  # depth = 0\n",
        "  # for i in range(len(s)):\n",
        "  #   if len(s[i]) != 0:\n",
        "  #     depth+=1\n",
        "  #   return depth\n",
        "\n",
        "#function to check the redirection\n",
        "def redirection(url):\n",
        "  c=0\n",
        "  for i in range(len(url)):\n",
        "    if url[i]=='/' and url[i+1]=='/':\n",
        "      c+=1\n",
        "      break\n",
        "    else:\n",
        "      c+=1\n",
        "  return 1 if c>6 else 0\n",
        "  # pos = url.rfind('//')\n",
        "  # if pos > 6:\n",
        "  #   if pos > 7:\n",
        "  #     return 1\n",
        "  #   else:\n",
        "  #     return 0\n",
        "  # else:\n",
        "  #   return 0\n",
        "\n",
        "#function to check the https domain\n",
        "def httpsDomain(url):\n",
        "  domain = urlparse(url).netloc\n",
        "  return 1 if 'https' in domain else 0\n",
        "\n",
        "#function to check sortening services\n",
        "shortening = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
        "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
        "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
        "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
        "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
        "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
        "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
        "                      r\"tr\\.im|link\\.zip\\.net\"\n",
        "def sort_url(url):\n",
        "  sort=re.search(shortening,url)\n",
        "  if sort:\n",
        "    return 2\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#function from prefix and suffix\n",
        "def prefix_suffix(url):\n",
        "  if '-' in urlparse(url).netloc:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#function to find web trafic\n",
        "def web_traffic(url):\n",
        "  try:\n",
        "    #Filling the whitespaces in the URL if any\n",
        "    response = requests.get(f\"https://www.alexa.com/siteinfo/{url}\")\n",
        "    response.raise_for_status()  # Check for any request errors\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    rank = soup.find(\"strong\", class_=\"metrics-data align-vmiddle\")\n",
        "    # url = urllib.parse.quote(url)\n",
        "    # rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
        "    #     \"REACH\")['RANK']\n",
        "    rank = int(rank)\n",
        "  except TypeError:\n",
        "        return 1\n",
        "  if rank <100000:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#function to find domain age\n",
        "def age(domain_name):\n",
        "  creation_date = domain_name.creation_date\n",
        "  expiration_date = domain_name.expiration_date\n",
        "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
        "    try:\n",
        "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
        "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
        "    except:\n",
        "      return 1\n",
        "  if ((expiration_date is None) or (creation_date is None)):\n",
        "    return 1\n",
        "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
        "    return 1\n",
        "  else:\n",
        "    ageofdomain = abs((expiration_date - creation_date).days)\n",
        "    if ((ageofdomain/30) < 6):\n",
        "      age = 1\n",
        "    else:\n",
        "        age = 0\n",
        "  return age\n",
        "\n",
        "#function to find the domain end\n",
        "def domain_end(domain_name):\n",
        "  expiration_date = domain_name.expiration_date\n",
        "  if isinstance(expiration_date,str):\n",
        "    try:\n",
        "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
        "    except:\n",
        "      return 1\n",
        "  if (expiration_date is None):\n",
        "      return 1\n",
        "  elif (type(expiration_date) is list):\n",
        "      return 1\n",
        "  else:\n",
        "    today = datetime.now()\n",
        "    end = abs((expiration_date - today).days)\n",
        "    if ((end/30) < 6):\n",
        "      end = 0\n",
        "    else:\n",
        "      end = 1\n",
        "  return end\n",
        "\n",
        "#function to find the Iframe\n",
        "def Iframe(response):\n",
        "  if response==\"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "#function to find the mouse over the status bar\n",
        "def mouse_over(response):\n",
        "  if response == \"\" :\n",
        "    return 1\n",
        "  else:\n",
        "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "#function to check the right click attributes\n",
        "def right_click(response):\n",
        "  if response == \"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "#function for finding web_forwarding\n",
        "def forward(response):\n",
        "  if response == \"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if len(response.history) <= 2:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "#main data's append in the list\n",
        "url=input()\n",
        "#creating empty list to store data\n",
        "data_url=[]\n",
        "#inserting the data_url to the list\n",
        "data_url.append(have_ip(url))\n",
        "data_url.append(have_at(url))\n",
        "data_url.append(length_url(url))\n",
        "data_url.append(url_depth(url))\n",
        "data_url.append(redirection(url))\n",
        "data_url.append(httpsDomain(url))\n",
        "data_url.append(sort_url(url))\n",
        "data_url.append(prefix_suffix(url))\n",
        "#finding the domain name\n",
        "dns = 0\n",
        "try:\n",
        "  domain_name = whois.whois(urlparse(url).netloc)\n",
        "except:\n",
        "  dns = 1\n",
        "data_url.append(dns)\n",
        "data_url.append(web_traffic(url))\n",
        "data_url.append(1 if dns == 1 else age(domain_name))\n",
        "data_url.append(1 if dns == 1 else domain_end(domain_name))\n",
        "#geting the response from the url\n",
        "try:\n",
        "  response=requests.get(url)\n",
        "except:\n",
        "  response=\"\"\n",
        "#inserting the informaition based on the response\n",
        "data_url.append(Iframe(response))\n",
        "data_url.append(mouse_over(response))\n",
        "data_url.append(right_click(response))\n",
        "data_url.append(forward(response))\n",
        "url_predict_data=[]\n",
        "url_predict_data.append(data_url)\n",
        "print(url_predict_data)\n",
        "\n",
        "\n",
        "# #checking the feature improtance in the model\n",
        "# plt.figure(figsize=(9,7))\n",
        "# n_features = X_train.shape[1]\n",
        "# plt.barh(range(n_features), tree.feature_importances_, align='center')\n",
        "# plt.yticks(np.arange(n_features), X_train.columns)\n",
        "# plt.xlabel(\"Feature importance\")\n",
        "# plt.ylabel(\"Feature\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "[[0, 0, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# machine learning\n",
        "#importing llb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "#load dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "#Dropping the Domain column\n",
        "data = df.drop(['Domain'], axis = 1).copy()\n",
        "# shuffling the data in the dataset\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "# Sepratating & assigning features and target columns to X & y\n",
        "#input data from the data set\n",
        "y = data['Label']\n",
        "X = data.drop('Label',axis=1)\n",
        "# Splitting the dataset into train and test sets: 80-20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "# Creating holders to store the model performance results\n",
        "ML_Model = []\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "#function to call for storing the results\n",
        "def storeResults(model, a,b):\n",
        "  ML_Model.append(model)\n",
        "  acc_train.append(round(a, 3))\n",
        "  acc_test.append(round(b, 3))\n",
        "# machine learning alg\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "url_predict_data_df = pd.DataFrame(columns=X_train.columns)\n",
        "# Populate the DataFrame with feature values for the URL you want to predict\n",
        "url_predict_data_df.loc[0] = data_url\n",
        "# instantiate the model\n",
        "tree = DecisionTreeClassifier(max_depth = 5)\n",
        "# fit the model\n",
        "tree.fit(X_train, y_train)\n",
        "#predicting the target value from the model for the samples\n",
        "y_test_tree = tree.predict(X_test)\n",
        "y_train_tree = tree.predict(X_train)\n",
        "acc_train_tree = accuracy_score(y_train,y_train_tree)\n",
        "acc_test_tree = accuracy_score(y_test,y_test_tree)\n",
        "prediction=tree.predict(url_predict_data_df)\n",
        "print(\"Phishing\" if prediction[0]==1 else \"Legitimate\")\n",
        "print(\"acc-train\",acc_train_tree)\n",
        "print(\"acc-test\",acc_test_tree)\n",
        "\n",
        "\n",
        "#Plotting the data distribution\n",
        "df.hist(bins = 50,figsize = (15,15))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Correlation heatmap\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df.corr())\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cwJHrDoP_1_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}